# 功能描述：
本程序是为了解决“人类手动去看贴吧的小说更新很浪费时间”的问题而设计的。它自动去爬取指定贴吧的置顶精品帖子（就是小说的更新），然后判断是否是更新的内容，若是，则发送邮件给你（也是可以在程序里自定义指定的）。节约时间可以好好学习！！！

但是，天有不测风云，我写完这个程序不到半个月，百度贴吧的小说类贴吧就全部被关闭清理了，据说是版权问题。现在又重新开启了，不过已经没有更新小说了。所以这个程序也就仅剩下参考功能了。


# 开发环境
python3 + ubuntu + Crontab
其中Crontab是ubuntu上的一个定时任务机制，用来设置定时指定这个脚本的。用法很简单，请自行搜索。


# 程序逻辑
1. 其实这个程序不太应该叫做爬虫，因为它只是爬取指定页面的内容。
2. 置顶精品贴的识别：查看html可以发现是有很明显的模式的，正则匹配即可：```<div class="threadlist_title[^>]*>\s*<i[^>]*></i>\s*<i[^>]*></i>\s*<a href="([^"]*)"[^>]*>\s*(.*?)\s*</a>\s*</div>```
3. 判断是否为更新：其实正规一点应该使用数据库的，不过考虑到一本小说最多也就2000章，杀鸡不需要牛刀，所以使用文件系统来存储也很简单维护。所以我是将历史的更新存储到一个文本A里，然后将新获取到的数据与历史数据对比，如果没有匹配的，说明就是更新了。
4. 如果邮件发送失败呢：很明显发送失败了，是不能将其内容写入文本A里的，因为这样下次就不会再发送这些没有发送成功的内容了！那应该怎么办呢？逻辑上这应该是一个原子操作：发送成功+写入文本A或者发送失败+不写入文本A。但是不写入文本A，应该怎么办呢？丢弃掉这些数据，然后等下一次爬取的时候再尝试发送？这样确实可以，但是有个问题就是——就常识来说，邮件服务器的故障一般是持续的，不会说马上一两分钟就解决。那万一它这个故障持续了挺久的，并且那些更新了却没有发送成功的数据被后来更新的数据给挤掉了（因为主页一般只有2-3个置顶贴），那这部分数据就真的丢失了！！！所以不能丢弃掉这些数据，但是又不能写入文本A里，那应该怎么办呢？我的做法是——还是写入文本A里，但是另外建立一个文本B来存储这些发送失败的数据，在每次检测的时候也检测是否有发送失败的数据并尝试重新发送，直到发送成功才将B中的数据清空。这样子相当于逻辑上是没有写入到文本A里的，但同时又保证了不会有因为邮件服务器故障时间的长短而导致数据丢失的问题！！！


# 代码结构
getData.py是主程序，在里面可自定义发送的邮箱列表、想要爬取的贴吧地址。

BDTieBa.py是封装的一个百度贴吧的类，里面是整个程序的主体逻辑。

send_email.py是一个发送邮件的功能函数，使用smtp协议发送邮件，需要自行申请或搭建一个邮件服务器来实现，当然，也可以换成另外的通讯模式，因为发送邮件是一个黑盒子，里面的功能逻辑可以随便改，对其它模块没有任何影响！！！（前提是返回值、参数等的约定保持一致）



